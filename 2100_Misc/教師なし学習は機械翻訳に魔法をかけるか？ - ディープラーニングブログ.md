---
title: 教師なし学習は機械翻訳に魔法をかけるか？ - ディープラーニングブログ
updated: 2018-04-28 10:27:05Z
created: 2018-04-28 10:27:05Z
source: http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation
tags:
  - null
---

# ディープラーニングブログ

## Mine is Deeper than yours!

つい先週，[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)で驚くべき進展がありました．

要約すると**教師なし学習でもひと昔前の教師あり学習の[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)に匹敵する性能を獲得**できたというのです．この記事では[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)を知らない初心者にもわかるように魔法のような教師なし[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)の仕組みを説明したいと思います．

### 教師あり学習の限界

[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)は[ディープラーニング](http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0)を適用することで急激に進歩した分野の１つだと思います．[Google](http://d.hatena.ne.jp/keyword/Google) 翻訳はニューラル[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)を導入することで非常に流暢な翻訳が可能になりました．これで[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)は解決した......かというと長文翻訳や同時通訳，マイナー言語対応など多くの研究課題が残されています．

![20180428101536.png](../_resources/20180428101536.png)

ところで翻訳モデルの学習には通常2言語間の対訳[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)が必要です．例えば日英翻訳ではこのような対訳[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)を準備します．翻訳元の日本語をソース文，翻訳先の英語をターゲット文と言います．

![20180428101459.png](../_resources/20180428101459.png)

翻訳モデルはソース文を入力として翻訳文を生成します．そして生成した翻訳文とターゲット文 (教師信号) との差異が小さくなるようにパラメータを更新することでソース文からターゲット文を生成する翻訳モデルを獲得します．

ここで問題となるのは翻訳モデルの学習には大量の対訳文が必要ということです．英仏や英独間には巨大な対訳[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)が存在しますが，多くのマイナー言語間ではほとんど対訳文が集まりません．そこでマイナー言語間は英語や[インターリングア](http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%BF%A1%BC%A5%EA%A5%F3%A5%B0%A5%A2) (人工的な[中間言語](http://d.hatena.ne.jp/keyword/%C3%E6%B4%D6%B8%C0%B8%EC)) を経由して翻訳するピボット翻訳が使われる場合が多いです．しかしこの場合でも英語 (もしくは[インターリングア](http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%BF%A1%BC%A5%EA%A5%F3%A5%B0%A5%A2)) とマイナー言語間には大量の対訳文が必要になります．**もし対訳[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)を作成する必要がなくなればマイナー言語間の翻訳が可能になるばかりか共通の構造を持つ世界間ならば容易に変換を学習**できるはずです．

マイナー言語でもその言語で書かれた文章を集めるのは容易なので，**対訳関係のない2言語[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)**なら簡単に作れます．この2言語[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)だけで翻訳モデルを学習することを**教師なし[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)** (Unsupervised Machine Translation) と言います．この場合[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)には対訳文 (教師信号) が存在しないので教師なし学習に分類されます．

教師なし学習によるニューラル[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)は昨年10月末に論文が投稿されたばかりの新しい技術です[*1](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-978c0e30)[*2](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-a4a388f5)．この論文で提案された手法は興味深いものでしたが，自動評価によるスコアは低く実験の域を脱していませんでした．

![20180428101527.png](../_resources/20180428101527.png)

仏英翻訳の例を載せました．いくつかの語句やフレーズの翻訳に成功していますが，実用とはほど遠い性能だとわかります．このとき私は教師なし[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)が日の目を見るまでにはあと数年かかるだろうと思いました．

状況が好転したのはつい先週です．教師なし[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)を提案した著者らが新しい論文を投稿しました[*3](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-e04872a3)．

![20180428101520.png](../_resources/20180428101520.png)

仏英翻訳の例を載せました．以前に比べかなりターゲット文に似た翻訳文を生成しています．**自動評価のスコアも 15 から 25 に劇的な改善**を果たしました．

### 魔法の正体

対訳関係のない2言語[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)からどうすれば翻訳モデルを学習できるのでしょうか？

教師あり学習では生成した翻訳文とターゲット文との誤差が小さくなるように学習しました．教師なし学習ではターゲット文 (教師信号) が与えられないので**別の教師信号を見つける**必要があります．ここで登場する1つ目のトリックが逆翻訳 (Back-translation) です．

![20180428101346.png](../_resources/20180428101346.png)

**逆翻訳はソース文をターゲット文に翻訳し，ターゲット文を元のソース文に再翻訳する手法**です[*4](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-5e5f6619)．優れた翻訳モデルはソース文と逆翻訳後のソース文が類似していることが期待されます．つまり**逆翻訳後のソース文にとって元のソース文は教師信号**だと解釈できます．ソース文を擬似的なターゲット文に翻訳し，擬似的なターゲット文をソース文に再翻訳すると，ソース文 (教師信号) と逆翻訳後のソース文との誤差が求まるのでこの誤差が小さくなるように学習します．これは最初の翻訳で擬似的なターゲット文とソース文のペアからなる対訳[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)を作成して次の翻訳で教師あり学習をしているのだと解釈できます (上図は英日翻訳モデルの学習例です．日英翻訳モデルも逆の手順で学習できます)．

しかしこのままでは翻訳モデルを正しく学習できません．学習初期の擬似的なターゲット文はノイズが多く不安定な文です．これを翻訳モデルに入力しても更に支離滅裂な文を生成することは容易に想像できます．これは翻訳モデルがノイズの多い入力からノイズを取り除く能力を持っていないためです．

![20180428101412.png](../_resources/20180428101412.png)

2つ目のトリックはノイズ除去 (Denoising) です．**ノイズ除去は入力文に語順の入れ替えや語句の欠損を施したノイジーな入力文から元の入力文への変換を学習**します．この場合も**ノイズ除去後の入力文にとって元の入力文は教師信号**だと解釈できます．ノイズ除去を事前に学習することで逆翻訳の途中で生成されるノイズの多いターゲット文はノイズを除去されながら逆翻訳後のソース文に翻訳されるはずです．

![20180428101419.png](../_resources/20180428101419.png)
![20180428101353.png](../_resources/20180428101353.png)

ここまでの話は10月末の論文で提案された手法です．結論から言うと，これだけではノイズ除去から逆翻訳への移行に失敗します．なぜでしょうか？ ヒントは潜在表現 (Latent Representation) です．

潜在表現は[ニューラルネットワーク](http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF)が理解できる言葉 (数値の羅列) です．翻訳翻訳で使用される[ニューラルネットワーク](http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF)であるエンコーダ・[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)モデルでは，エンコーダがソース文 (もしくはターゲット文) を潜在表現に変換し，[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)が潜在表現をターゲット文 (もしくはソース文) に変換します．

![20180428101426.png](../_resources/20180428101426.png)

今のところモデルには一切制約が与えられていないので**ノイズ除去で獲得される潜在表現と翻訳で獲得される潜在表現は異なるエリア (=部分空間) を使用**します．したがって日本語[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)は日本語エンコーダ由来の潜在表現に対してノイズ除去だけを，英語エンコーダ由来の潜在表現に対して翻訳だけを実施すれば十分損失を最小化できました．理想的には日本語[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)はノイズ除去と翻訳を同時に行うべきですが実際には片方しか行わない状態でした．

10 月末の論文でも**潜在表現を共有するための制約**が必要なことはわかっていました．2種類の異なる制約が提案されましたが，どちらの制約も十分に機能せず潜在表現の分離を解消できませんでした[*5](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-6ef1243a)．

### [たったひとつの冴えたやりかた](http://d.hatena.ne.jp/keyword/%A4%BF%A4%C3%A4%BF%A4%D2%A4%C8%A4%C4%A4%CE%BA%E3%A4%A8%A4%BF%A4%E4%A4%EA%A4%AB%A4%BF)

潜在表現を共有するためにはどんな制約が必要でしょうか？

10 月末の論文では日本語エンコーダと英語エンコーダのパラメータを共有することで，日本語を[エンコード](http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%B3%A1%BC%A5%C9)した潜在表現と英語を[エンコード](http://d.hatena.ne.jp/keyword/%A5%A8%A5%F3%A5%B3%A1%BC%A5%C9)した潜在表現が同じ空間を使用するような制約を採用しました．

この方法は[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)が入力言語に関わらず同様に動作することを促しましたが制約として不十分でした．依然として日本語[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)と英語[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)は別れたままなので，日本語のノイズ除去と英語のノイズ除去は異なる部分空間を使用して学習できました．

![20180428103912.png](../_resources/20180428103912.png)

新しい論文では**翻訳モデルのすべてパラメータを共有**しました．つまり日本語エンコーダと英語エンコーダを共有し，日本語[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)と英語[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)も共有しました．また，サブワードの埋め込み表現をもつエンコーダの埋め込み層や[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)のソフトマックス層も共有しました[*6](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-7c4012d0)．

文字通りすべてのパラメータを共有するという強力な制約によって，ようやく**日本語由来と英語由来の潜在表現は一体化し，ノイズ除去からノイズの多い逆翻訳への移行に成功**しました．教師なし学習でも流暢な翻訳が可能になったのです．

この新しい論文のアプローチは [Google](http://d.hatena.ne.jp/keyword/Google) ニューラル[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)の zero-shot 翻訳の影響を受けたものです[*7](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-f92379f5)．zero-shot 翻訳では多言語間で翻訳モデルを共有し，[デコーダ](http://d.hatena.ne.jp/keyword/%A5%C7%A5%B3%A1%BC%A5%C0)が複数のターゲット言語を生成するために共有のサブワードを使用します．注目すべきは翻訳モデルとサブワードの共有によって潜在表現が共有されることを可視化した点です．

![20180428101510.png](../_resources/20180428101510.png)

英日韓翻訳を学習したモデルを用いて潜在表現を[クラスタリング](http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF%A5%EA%A5%F3%A5%B0)した例を載せました．(a) は74種類の，英日韓で同一の意味を表す文を74色の[クラスタ](http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF)に別けたものです．(b) は英日韓ともに「[成層圏](http://d.hatena.ne.jp/keyword/%C0%AE%C1%D8%B7%F7)は、高度10kmから50kmの範囲にあります．」という意味を表す文の[クラスタ](http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF)であり，(c) は英日韓で色分けしています．**同一の意味を表す文の潜在表現が共有されている**ことが確認できます．

教師なし日英翻訳を行うためには日英間で共有できるサブワードがあまり存在しないという問題があります．とはいえ zero-shot 翻訳では数字・日付・名前・ウェブサイト・句読点などが共通の ASCII を使用するので予想よりも多くのサブワードを共有でき，それほど厄介な問題にならなかったようです．

![20180428101403.png](../_resources/20180428101403.png)

逆翻訳は教師なし画風変換の CycleGAN に似た学習方法と言えます[*8](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#f-e74cf1fe)．CycleGAN は2つの[ドメイン](http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3)間の，**各画像間にペア関係がないデー[タセット](http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8)間から同じ構図の画風変換を学習**します．例えば馬画像だけを集めたデー[タセット](http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8)とシマウマ画像だけを集めたデー[タセット](http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8)から馬→シマウマの変換やシマウマ→馬の変換を学習します．

CycleGAN でも馬をシマウマに変換してシマウマを馬に再変換し，逆変換後の馬と元の馬との誤差を最小化します．これは逆翻訳とまったく同じ思想です．今後，画像とテキスト間の教師なし変換が可能になるかもしれません．

[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)は[ディープラーニング](http://d.hatena.ne.jp/keyword/%A5%C7%A5%A3%A1%BC%A5%D7%A5%E9%A1%BC%A5%CB%A5%F3%A5%B0)に出会うことで急速な技術革新が起きています．[機械翻訳](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%CB%DD%CC%F5)の最新の研究を追うことで新しい発見があると私は信じています．また，おもしろい研究があれば紹介したいと思います．以上です．

![20180428101449.png](../_resources/20180428101449.png)

[人工知能](http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD)が魔法によって力を得ているサムネ画像です．お気になさらず．

[*1](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-978c0e30):Unsupervised Neural Machine Translation [[arXiv](http://d.hatena.ne.jp/keyword/arXiv): 1710.11041]

[*2](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-a4a388f5):Unsupervised Machine Translation Using Monolingual Corpora Only [[arXiv](http://d.hatena.ne.jp/keyword/arXiv): 1711.00043]

[*3](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-e04872a3):Phrase-Based & Neural Unsupervised Machine Translation [[arXiv](http://d.hatena.ne.jp/keyword/arXiv): 1804.07755]

[*4](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-5e5f6619):Improving Neural Machine Translation Models with Monolingual Data [[arXiv](http://d.hatena.ne.jp/keyword/arXiv): 1511.06709]

[*5](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-6ef1243a):1つは日本語エンコーダと英語エンコーダのパラメータを共有して潜在表現の共有化を図る方法，もう1つは敵対的学習によって潜在表現を近似する方法です

[*6](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-7c4012d0):例えば「something」という単語を分割した「some」と「thing」のような単語をサブワードと言います．新しい論文ではソース言語とターゲット言語の[コーパス](http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9)を混合した Byte Pair Encoding によってサブワードを作成しています．英仏の場合，95 %以上のサブワードを共有します

[*7](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-f92379f5):[Google](http://d.hatena.ne.jp/keyword/Google)'s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation [[arXiv](http://d.hatena.ne.jp/keyword/arXiv): 1611.04558]

[*8](http://deeplearning.hatenablog.com/entry/unsupervised_machine_translation#fn-e74cf1fe):Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks [[arXiv](http://d.hatena.ne.jp/keyword/arXiv): 1703.10593]

Measure
Measure