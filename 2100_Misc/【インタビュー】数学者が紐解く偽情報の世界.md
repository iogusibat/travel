---
title: 【インタビュー】数学者が紐解く偽情報の世界
updated: 2021-09-03 09:14:35Z
created: 2021-09-03 09:14:35Z
source: >-
  https://jp.techcrunch.com/2021/09/03/2021-08-20-a-mathematician-walks-into-a-bar-of-disinformation/
---

![](https://jp.techcrunch.com/wp-content/uploads/2021/09/GettyImages-1229862829.jpg?w=738)

偽情報に誤報、インフォテイメントにalgowars（アルゴワーズ）。メディアの未来をめぐるここ数十年間の議論に意味があるとすれば、少なくとも言語には刺激的な痕跡を残したということだろう。個人の心理的状態や神経学的な問題から、民主主義社会についてのさまざまな懸念まで、ソーシャルメディアが我々の社会にもたらす影響に関するあらゆる非難と恐怖がここ何年もの間、世間を渦巻いている。[最近Joseph Bernstein（ジョセフ・バーンスタイン）氏が語った通り](https://harpers.org/archive/2021/09/bad-news-selling-the-story-of-disinformation/)「群衆の知恵」から「偽情報」へのシフトというのは確かに急激なものだったと言えるだろう。

そもそも偽情報とは何なのか。それは存在するのか、存在するとしたらそれはどこにあるのか、どうすればそれが偽情報だとわかるのか。お気に入りのプラットフォームのアルゴリズムが私たちの注意を引きつけようと必死に見せてくる広告に対して我々は警戒すべきなのか？[Noah Giansiracusa（ノア・ジアンシラクサ）氏](https://www.noahgian.com/)がこのテーマに興味を持ったのは、まさにこのよう入り組んだ数学的および社会科学的な疑問からだった。

ボストンにあるベントレー大学の教授であるジアンシラクサ氏は、代数幾何学などの数学を専門としているが、[計算幾何学と最高裁を結びつける](https://arxiv.org/abs/1810.11704)など、社会的なトピックを数学的なレンズを通して見ることにも興味を持っていた。最近では「[How Algorithms Create and Prevent Fake News（アルゴリズムがフェイクニュースを生み、防ぐ仕組み）](https://www.apress.com/us/book/9781484271544)」という本を出版。著書では今日のメディアをめぐる課題と、テクノロジーがそれらの傾向をどのように悪化させたり改善したりしているかを探求している。

先日筆者はTwitter Spaceでジアンシラクサ氏をお招きしたのだが、何とも儚いTwitterではこのトークを後から簡単に聴くことができないため、読者諸君と後世のためにも会話の中で最も興味深い部分を抜き出してみることにした。

*このインタビューはわかりやすくするために編集、短縮されている。*
**ダニー・クライトン：**フェイクニュースを研究し、この本を書こうと思った理由を教えてください。

**ノア・ジアンシラクサ：**フェイクニュースについては社会学や政治学の分野で非常に興味深い議論がなされています。一方でテック系サイドではMark Zuckerberg（マーク・ザッカーバーグ）氏が「AIがすべての問題を解決してくれる」などと言っています。このギャップを埋めるのは少し難しいのではないかと感じました。

ソーシャルメディア上の誤報について、バイデン大統領が「[誤報が人を殺している](https://www.nytimes.com/2021/07/16/us/politics/biden-facebook-social-media-covid.html)」と言ったのを耳にしたことがあるでしょう。このように、アルゴリズムの側面を理解するのが難しい政治家たちはこのようなことを話しているのです。一方、コンピューターサイエンスの専門家らは細部にまで精通しています。私は筋金入りのコンピューターサイエンスの専門家ではないので、その中間にいると言えるでしょう。ですから一歩下がって全体像を把握することが私には比較的簡単にできると思っています。

それに何と言っても、物事が混乱していて、数学がそれほどきれいではない社会との相互作用をもっと探究したいと思ったのです。

**クライトン：**数学のバックグラウンドを持つあなたが、多くの人がさまざまな角度から執筆しているこの難しい分野に足を踏み入れています。この分野では人々は何を正しく理解しているのでしょうか。また、人々が見落としているものとは何でしょうか。

**ジアンシラクサ：**すばらしいジャーナリズムがたくさんあります。多くのジャーナリストがかなり専門的な内容を扱うことができていることに驚かされました。しかし、おそらく間違っているわけではないのですが、1つだけ気になったことがあります。学術論文が発表されたり、GoogleやFacebookなどのハイテク企業が何かを発表したりするときに、ジャーナリストたちはそれを引用して説明しようとするのですが、実際に本当に見て理解しようとすることを少し恐れているように見えました。その能力がないのではなく、むしろ恐怖を感じているのだと思いました。

私が数学の教師として大いに学んだことですが、人々は間違ったことを言ったり、間違えたりすることをとても恐れています。これは技術的なことを書かなければならないジャーナリストも同じで、間違ったことを言いたくないのです。だからFacebookのプレスリリースを引用したり、専門家の言葉を引用したりする方が簡単なのでしょう。

数学が純粋に楽しく美しい理由の1つは、間違いなどを気にせずアイデアを試してみて、それがどこにつながっていくのかを体験することで、さまざまな相互作用を見ることができるということです。論文を書いたり講演をしたりするときには、詳細をチェックします。しかし数学のほとんどは、アイデアがどのように相互作用するかを見極めながら探求していく、この創造的なプロセスなのです。私は数学者としての訓練を受けてきたので、間違いを犯すことや非常に正確であることを気にかけていると思うかもしれませんが、実はそれはとは逆の効果があるのです。

それから、これらのアルゴリズムの多くは見た目ほど複雑ではありません。私が実際に実行しているわけではありませんし、プログラムを組むのは難しいでしょう。しかし、全体像を見ると最近のアルゴリズムのほとんどはディープラーニングに基づいています。つまりニューラルネットワークがあり、それがどんなアーキテクチャを使っているかは外部の人間として私にはどうでもよく、本当に重要なのは予測因子は何なのかということです。要するにこの機械学習アルゴリズムに与える変数は何か、そして何を出力しようとしているのか？誰にでも理解できることです。

**クライトン：**アルゴリズムを分析する上での大きな課題の1つは透明性の低さです。問題解決に取り組む学者コミュニティの純粋数学の世界などとは異なり、これらの企業の多くは、データや分析結果を広く社会に提供することについて実際には非常に否定的です。

**ジアンシラクサ：**外部からでは、推測できることには限界があるように感じます。

YouTubeの推薦アルゴリズムが人々を過激派の陰謀論に送り込むかどうかを学者チームが調べようとしていましたが、これは良い例です。これが非常に難しいのは、推薦アルゴリズムにはディープラーニングが使われており、検索履歴や統計学、視聴した他の動画や視聴時間など、何百もの予測因子に基づいているためです。あなたとあなたの経験に合わせて高度にカスタマイズされているので、私が見つけた研究ではすべてシークレットモードが使用されていました。

検索履歴や情報を一切持たないユーザーが動画にアクセスし、最初におすすめされた動画をクリックし、またその次の動画をクリックする。そのようにしていけばアルゴリズムが人をどこへ連れて行くのかを確認することができるでしょう。しかしこれは履歴のある実際のユーザーとはまったく異なる体験ですし、とても難しいことです。外部からYouTubeのアルゴリズムを探る良い方法は誰も見つけられていないと思います。

正直なところ、私が考える唯一の方法は、大勢のボランティアを募り、その人たちのコンピューターにトラッカーを取り付けて「インターネットを普段通り閲覧して、見ている動画を教えてください」と頼む昔ながらの研究方法です。このように、ほとんどすべてと言っていいほど多くのアルゴリズムが個人のデータに大きく依存しているという事実を乗り越えるというのはとても困難なことです。私たちはまだどのように分析したら良いのか分かっていないのです。

データを持っていないために問題を抱えているのは、私やその他の外部の人間だけではありません。アルゴリズムを構築した企業内の人間も、そのアルゴリズムがどのように機能するのか理論上はわかってはいても、実際にどのように動作するのかまでは知らないのです。まるでフランケンシュタインの怪物のように、作ったはいいがどう動くかわからないわけです。ですから本当の意味でデータを研究するには、そのデータを持っている内部の人間が、時間とリソースを割いて研究するしかないと思います。

**クライトン：**誤報に対する評価やプラットフォーム上のエンゲージメントの判断には多くの指標が用いられています。あなたの数学的なバックグラウンドからすると、こういった指標は強固なものだと思いますか？

**ジアンシラクサ：**人々は誤った情報を暴こうとします。しかし、その過程でコメントしたり、リツイートしたり、シェアしたりすることがあり、それもエンゲージメントとしてカウントされます。エンゲージメントの測定では、ポジティブなものをきちんと把握しているのか、それともただすべてのエンゲージメントを見ているのか？すべて1つにまとめられてしまうでしょう。

これは学術研究においても同様です。被引用率は研究がどれだけ成功したものかを示す普遍的な指標です。例えばウェイクフィールドの自閉症とワクチンに関する論文は、まったくインチキなのにも関わらず大量に引用されていました。その多くは本当に正しいと思って引用している人たちですが、その他の多くはこの論文を否定している科学者たちです。しかし引用は引用です。つまり、すべてが成功の指標としてカウントされてしまうのです。

そのためエンゲージメントについても、それと似たようなことが起きているのだと思います。私がコメントに「それ、やばいな」と投稿した場合、アルゴリズムは私がそれを支持しているかどうかをどうやって知ることができるでしょう。AIの言語処理を使って試すこともできるかもしれませんが、そのためには大変な労力が必要です。

**クライトン：**最後に、GPT-3や合成メディア、フェイクニュースに関する懸念について少しお話したいと思います。AIボットが偽情報でメディアを圧倒するのではないかという懸念がありますが、私たちはどれくらい怖がるべきなのか、または恐れる必要はないのか、あなたの意見を教えてください。

**ジアンシラクサ：**私の本は体験から生まれたものなので、公平性を保ちながら人々に情報を提供して、彼らが自分で判断できるようにしたいと思いました。そのような議論を省いて、両方の立場の人に話してもらおうと思ったのです。私はニュースフィードのアルゴリズムや認識アルゴリズムは有害なものを増幅させ、社会に悪影響を与えると思います。しかしフェイクニュースを制限するためにアルゴリズムを生産的にうまく使っているすばらしい進歩もたくさんあります。

AIがすべてを解決し、真実を伝えて確認し、誤った情報を検出してそれを取り消すことができるアルゴリズムを手に入れることができるというテクノユートピア主義の人々がいます。わずかな進歩はありますが、そんなものは実現しないでしょうし、完全に成功することもありません。常に人間に頼る必要があるのです。一方で、もう1つの問題は不合理な恐怖心です。アルゴリズムが非常に強力で人間を滅ぼすという、誇張されたAIのディストピアがあります。

2018年にディープフェイクがニュースになり、GPT-3が数年前にリリースされた際「やばい、これではフェイクニュースの問題が深刻化して、何が真実かを理解するのがずっと難しくなってしまう」という恐怖が世間を取り巻きました。しかし数年経った今、多少難しくなったと言えるものの、予想していたほどではありません。主な問題は何よりも心理的、経済的なものなのです。

GPT-3の創造者らはアルゴリズムを紹介した研究論文を発表していますが、その中で、あるテキストを貼り付けて記事へと展開させ、ボランティアに評価してもらいどれがアルゴリズムで生成された記事で、どれが人間が生成した記事かを推測してもらうというテストを行いました。その結果、50％に近い精度が得られたと報告されています。すばらしくもあり、恐ろしいことでもありますね。

しかしよく見ると、この場合は単に1行の見出しを1段落の文章に展開させたに過ぎません。もしThe Atlantic誌やNew Yorker誌のような長文の記事を書こうとすると、矛盾が生じ、意味をなさなくなるかもしれません。この論文の著者はこのことには触れておらず、ただ実験をして「見て、こんなにも上手くいったよ」と言っただけのことです。

説得力があるように見えますし、なかなかの記事を作ることは可能です。しかしフェイクニュースや誤報などについて言えば、なぜGPT-3がさほど影響力がなかったかというと、結局のところそれはフェイクニュースがほとんどクズ同然だからです。書き方も下手で、質が低く、安っぽくてインスタントなものだからです。16歳の甥っ子にお金を払えば、数分で大量のフェイクニュース記事を作ることができるでしょう。

数学のおかげでこういったことを理解できるというよりも、数学では主に懐疑的になることが重要だから理解できるのかもしれません。だからこういったことに疑問を持ち、少し懐疑的になったら良いのです。

関連記事

・[米国政府・自治体はアップルとグーグル共同開発のコロナ接触通知APIを活用できず大失敗との調査結果](https://jp.techcrunch.com/2021/08/30/apple-google-exposure-api-failed-us/)

・[YouTubeは2020年2月以降、新型コロナに関する100万の危険な誤情報動画を削除](https://jp.techcrunch.com/2021/08/26/2021-08-25-youtube-has-removed-1-million-videos-for-dangerous-covid-19-misinformation/)

・[ツイッターはユーザーに新型コロナと選挙の誤情報報告を依頼](https://jp.techcrunch.com/2021/08/18/2021-08-17-twitter-report-misinformation/)

画像クレジット：Valera Golovniov/SOPA Images/LightRocket / Getty Images

［[原文へ](https://techcrunch.com/2021/08/20/a-mathematician-walks-into-a-bar-of-disinformation/)］

（文：Danny Crichton、翻訳：Dragonfly）

 TechCrunch Japanの最新記事を購読しよう