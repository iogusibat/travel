---
title: 機械学習
updated: 2016-12-15 13:44:50Z
created: 2016-12-05 11:10:53Z
source: >-
  https://www.system-i-enter.com/blog/blog/2016/07/07/%e3%80%90%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%80%91%e3%82%b7%e3%83%b3%e3%83%97%e3%83%ab%e3%81%aa%e5%9b%9e%e5%b8%b0%e5%88%86%e6%9e%90%e3%81%ae%e4%be%8b/
tags:
  - SI
---

http://qiita.com/m-hayashi/items/955856b3e2d6b3c42755

# 【機械学習】シンプルな回帰分析の例

こんにちは。R&Dチームの林です。
最近は機械学習の分野では、Amazon/Google/Microsoft など
世界のIT企業のトップが積極的にプラットフォームを提供しており、
ディベロッパーが機械学習を導入するハードルも下がりつつあります。
しかしながら、プラットフォームやツールの使い方は習得しても
その裏側のアルゴリズムの理解については、まだまだハードルが
高いイメージもあるかと思います。
ただ、高度な数学的な知識が必要となる部分もありますが
基本原理は高校数学レベルで理解できる部分もあります。
今回はその中でシンプルな「回帰分析」という解析手法の例を紹介します。
その前に機械学習の基本概念について少し触れておきます。

* * *

### ■「教師あり学習」と「教師なし学習」

機械学習のモデルは大きく分けて「教師あり学習」と「教師なし学習」があります。
「教師あり学習」はお手本となる「教師データ」を用意し，
そのデータに沿って，将来起こりそうな事象を予測します。
機械学習のサービスの大半は、この「教師あり学習」のモデルです。
「教師なし学習」は判断するための教師データはありません。
解析対象のデータに存在する特徴を探し出し、データの似た者同士を
グループ分けする用途で使用されます。
これ以外にも「半教師あり学習」や「強化学習」と呼ばれる
モデルもありますが、今回は説明を割愛します。

* * *

### ■「回帰」と「分類」

「教師あり学習」モデルでは「回帰」と「分類」という基本概念があります。
「回帰」とは、簡単に言うと「数値予測」です。
過去の入力数値から未来の数値を予測する概念です。
たとえば、「明日の日経平均株価はいくら？」とか
「明日の最高気温は何度？」などの予測をイメージしてもらうと
わかりやすいかと思います。
「分類」は、過去の入力数値を元に、新たに与えられたデータを
グループに仕分けする概念です。
迷惑メールフィルターがイメージしやすいモデルかと思います。

* * *

### ■「回帰分析」

数値予測の「回帰」にフォーカスすると、回帰分析という数学的なアプローチがあります。
回帰分析とは、計測データをグラフ化したときに、それにフィットする関数を予測する方法です。
その中でも機械学習サービスは「線形回帰（linear regression）」という
数学モデルを用いています。
今回はまずは、最もシンプルな回帰分析の例で
最小二乗法で直線を推定する方法を紹介します。
つまり、下図のような、赤点のプロットデータ（x,y）に
対して、青い破線の直線の一次方程式を求める方法です。
![figure_1.png](../_resources/figure_1.png)
＜一次方程式での推定＞
![yaxb.png](../_resources/yaxb.png)
この方程式のaとbの値を算出することで、
先のxの値に対するyの値を推測できるようになります。
どのような直線が相応しいものかの1つの考え方として
直線と各データプロットの距離の和が最小になるように考えます。
つまり、下図のようにデータプロットの赤点と、
直線上の黄点を結んだ緑線の長さに着目します。
直線との距離の誤差が最小になるようにするイメージです。
![figure_2.png](../_resources/figure_2.png)
各赤点の座標を以下のように表現します。
![xiyi123.png](../_resources/xiyi123.png)
ちなみにプロットの赤点の各座標は、以下の通りです。
![xy012345.png](../_resources/xy012345.png)
プロット赤点（Xi, Yi)と直線上の黄点の数値差をDiとすると、
![Di.png](../_resources/Di.png)
と書けます。
ただ、この数値差Diは正負のどちらにも成りえますので、それらを足し合わせても
最小値の評価には成りえません。
なのでDiを二乗した総和Sで評価します。
![Sab.png](../_resources/Sab.png)
さらに、このS(a,b)に上記の、(X0, Y0)…(X5, Y5)の
実データを入れて計算すると、以下のような形に展開されます。
![Sab2.png](../_resources/Sab2.png)
つまり、以下の2変数関数S(a,b)を最小にする、aとbを求めればよいことになります。
![Sab3.png](../_resources/Sab3.png)
2変数関数の最小値を求める場合は、高校数学で学習する
[偏微分](http://mathtrain.jp/henbibunimi)を用います。
S(a,b) が最小になるポイントでは、a,bでそれぞれ偏微分した値は0になります。
![henbibun.png](../_resources/henbibun.png)
上記はa,bの連立方程式となりましたのでそれを解くと、aとbは以下の値になります。
![resolved_ab.png](../_resources/resolved_ab.png)
つまり、以下の1次関数が求める直線になります。
![resolved_func.png](../_resources/resolved_func.png)
![figure_4.png](../_resources/figure_4.png)
計測データには、X=6のデータはありませんが、この推測した関数を用いると、
Y = 1.4 × 6 + 2 = 10.4という数値を予測できることになります。
ただ、今回の解析は仮説ベースのものであることも忘れてはならないポイントです。
計測されたデータ群が関数に当てはめることができること自体も
仮説でありますし、それをさらに今回は直線と仮定したところも
強い縛りのある仮説になります。
ただ、仮説というモデルがなければ、収集されたデータ群から予測解析はできません。
つまり、機械学習を導入する上ではモデルの設計が重要なポイントです。
また、機械学習は厳密さをある程度割り切って「計算できる」ことに重点をおく
思想であることも重要なポイントだったりします。
今回のお話はここまで！
弊社開発実績は[こちら](http://www.system-i-enter.com/result/index-iPhone_iPad.php)になります。